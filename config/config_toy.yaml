itemset_mining_preparation:
  window_size: 10
  ignore_win_smaller_than: 0.5 # percentage of window size
  windowing_method: beta1 #implemented methods: mean-max, mean-std, mean-mean, energy, range, eucl_dist,eucl_zero_shot, n_peaks, beta1
  enable_threshold_tuning: False # if True, use train part of data to find the best threshold (zero-shot learning)
  train_size: 100
  threshold_tuning_step: 0.2 # start from one and step up by this
  custom_threshold: 0.5 # not used if threshold tuning is enabled
  compare_to_train_for_detection: True #use parameters (e.g., mean) calculated across train data as base as ooposed to the whole data
  cut_baseline: True # cut quantile of ....
  quantile: 0.65
  utility_function: max # implemented: max, sum
  cons_trans_chk_for_merge: 4 # number of consecutive anomalies to check for merging (into one with higher utility)
spmf:
  algorithm: LCM # from: Apriori, FPGrowth_itemsets,AprioriTID_Bitset,Eclat,dEclat,HMine,FIN,DFIN,NegFIN,PrePost+,PrePost,LCMFreq,AprioriClose,DCI_Closed,Charm_bitset,LCM,FPClose,NAFCP,NEclatClosed,FPMax,Charm_MFI,DefMe,Pascal,Zart,AprioriRare,Two-Phase,FHM, EFIM,CHUI-MinerMax,AprioriInverse,AprioriInverse_TID
  min_support: 0.5%
  max_support: 1% # for AprioriInverse
  min_support_count: 1 # for algos that expect integer support count
  max_pattern_length: 3
  min_pattern_length: 1
  show_transaction_ids: False #for algorithms that return TIDs
  high_utility_itemsets: False # For high utility mining algos
  min_utility: 1 # for high utility mining algos
  sort_input_items: #  some algos require sorted items
    enable: True
    ascending: True
  replace_zero: # some algos can only handle positive integers
    enable: False
    replace_zero_with: 1000
  jar_file: ./lib/spmf.jar

anomalyscoring:
  which: matrixprofile
  matrixprofile:
    subsequence_length: 10 # to calculate z-normalized Euclidean distance
    auto_subsequence_length: False # if True, the subsequence_length will not be used
  iForest:
    num_trees: 100
data:
  dataset_title: toy
  dataset_file_name: toy_data.csv
  dataset_gt_file_name: toy_data_GT.csv
  ground_truth_type: range # or "point" for each anomaly
  data_gt_single_file: False # if true, the gt_file_name is not read
  dataset_path: ./data/raw/toy/
  spmf_output_path: ./data/output/spmf/
  final_output_path: ./data/output/final/
  processed_data_path: ./data/processed/
  transactions_path: ./data/processed/saved_transactions/
  scores_path: ./data/processed/saved_scores/
  transaction_db_path: ./data/processed/transaction_databases/
  label_pad_size: 5
logging:
  console_log_level: INFO
  log_dir: ./logs/
  log_file_prefix: dev
plot:
  output_path: ./plots/
  subplot_size: 160
  show_dataset: False
  show_matrixprofile: False
  show_kdp: False
  show_detected_anomalies_vs_gt: False
  show_final_output: False
